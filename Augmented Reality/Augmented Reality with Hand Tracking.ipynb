{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed851cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\rakib\\appdata\\roaming\\python\\python39\\site-packages (0.8.10)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\rakib\\anaconda3\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\rakib\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rakib\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde6e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import interp\n",
    "import uuid\n",
    "import os\n",
    "from typing import Mapping, Tuple\n",
    "from mediapipe.python.solutions import drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34661869",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9494feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColor(zDist):\n",
    "    print(zDist)\n",
    "    c = int(interp(zDist, [0,15], [0,255]))\n",
    "    return (c,c,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8a1887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLandMarks(hand_landmarks): #-> Mapping[int, mp_drawing.DrawingSpec]:\n",
    "  hand_landmark_style = {}  \n",
    "  for k, v in drawing_styles._HAND_LANDMARK_STYLE.items():\n",
    "    for landmark in k:\n",
    "      c = getColor(abs(hand_landmarks.landmark[landmark].z*100))\n",
    "      r = int(abs(hand_landmarks.landmark[landmark].z*100))\n",
    "      hand_landmark_style[landmark] =   mp_drawing.DrawingSpec(color=c, thickness=drawing_styles._THICKNESS_DOT, circle_radius= r )\n",
    "  return hand_landmark_style   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6579c7",
   "metadata": {},
   "source": [
    "# Draw Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31dd8a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(static_image_mode=False,min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         print('Handedness:', results.multi_handedness)\n",
    "\n",
    "        #Get image H ,W\n",
    "        image_height, image_width, _ = image.shape\n",
    "        \n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand_landmarks  in enumerate(results.multi_hand_landmarks):\n",
    "#                 print('hand_landmarks:', hand_landmarks)\n",
    "                print(\n",
    "                    f'Index finger tip coordinates: (',\n",
    "                    f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "                    f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height}) '\n",
    "                    f'{abs(hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].z*100)})'\n",
    "                )\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "#                                         mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "#                                         mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),)\n",
    "                                      createLandMarks(hand_landmarks),\n",
    "                                      mp_drawing_styles.get_default_hand_connections_style())\n",
    "                    \n",
    "        plot = np.zeros([image_height, image_width, 3], dtype=np.uint8)                \n",
    "        if results.multi_hand_world_landmarks:\n",
    "            for num,hand_world_landmarks in enumerate(results.multi_hand_world_landmarks):                \n",
    "                for idx,landMrk in enumerate(hand_world_landmarks.landmark):\n",
    "                    hand_world_landmarks.landmark[idx].x += 0.5\n",
    "                    hand_world_landmarks.landmark[idx].y += 0.5\n",
    "                mp_drawing.draw_landmarks(plot,hand_world_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "#                 mp_drawing.plot_landmarks(hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)\n",
    "        \n",
    "        cv2.imshow('Plot', plot)\n",
    "        cv2.imshow('Hand Tracking', image)        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "138e3961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting camera\n",
      "  Downloading camera-1.3.0.tar.gz (1.3 kB)\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.1.2-cp39-cp39-win_amd64.whl (8.4 MB)\n",
      "Collecting PyOpenGL\n",
      "  Downloading PyOpenGL-3.1.6-py3-none-any.whl (2.4 MB)\n",
      "Building wheels for collected packages: camera\n",
      "  Building wheel for camera (setup.py): started\n",
      "  Building wheel for camera (setup.py): finished with status 'done'\n",
      "  Created wheel for camera: filename=camera-1.3.0-py3-none-any.whl size=1797 sha256=ac53b9b80f6d039302c6cb23b22db97c26543712beff8587c6e150c8ced14548\n",
      "  Stored in directory: c:\\users\\rakib\\appdata\\local\\pip\\cache\\wheels\\bb\\3b\\74\\5f188f33882c695e8fdaceb3f3a06775bb5c4cc87f058020ec\n",
      "Successfully built camera\n",
      "Installing collected packages: PyOpenGL, pygame, camera\n",
      "Successfully installed PyOpenGL-3.1.6 camera-1.3.0 pygame-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install camera pygame PyOpenGL\n",
    "import time, threading\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d96943c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: camera in c:\\users\\rakib\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: pygame in c:\\users\\rakib\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: PyOpenGL in c:\\users\\rakib\\anaconda3\\lib\\site-packages (3.1.6)\n",
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "!pip install camera pygame PyOpenGL\n",
    "import time, threading\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from numpy import interp\n",
    "import uuid\n",
    "from typing import Mapping, Tuple\n",
    "from mediapipe.python.solutions import drawing_styles\n",
    "import pygame\n",
    "from OpenGL.GL import *\n",
    "\n",
    "# Minimum number of matches that have to be found\n",
    "# to consider the recognition valid\n",
    "MIN_MATCHES = 15\n",
    "DEFAULT_COLOR = (0, 255, 0)\n",
    "# load the reference surface that will be searched in the video stream\n",
    "dir_name = os.getcwd()\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955362f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MTL(filename):\n",
    "    contents = {}\n",
    "    mtl = None\n",
    "    for line in open(filename, \"r\"):\n",
    "        if line.startswith('#'): continue\n",
    "        values = line.split()\n",
    "        if not values: continue\n",
    "        if values[0] == 'newmtl':\n",
    "            mtl = contents[values[1]] = {}\n",
    "        elif mtl is None:\n",
    "            raise ValueError(\"mtl file doesn't start with newmtl stmt\")\n",
    "        elif values[0] == 'map_Kd':\n",
    "            # load the texture referred to by this declaration\n",
    "            mtl[values[0]] = values[1]\n",
    "            surf = pygame.image.load(\"/\".join(list(filename.split('/')[0:-1]))+\"/\"+mtl['map_Kd'])\n",
    "            image = pygame.image.tostring(surf, 'RGBA', 1)\n",
    "            ix, iy = surf.get_rect().size\n",
    "            texid = mtl['texture_Kd'] = glGenTextures(1)\n",
    "            glBindTexture(GL_TEXTURE_2D, texid)\n",
    "            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,\n",
    "                GL_LINEAR)\n",
    "            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,\n",
    "                GL_LINEAR)\n",
    "            glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, ix, iy, 0, GL_RGBA,\n",
    "                GL_UNSIGNED_BYTE, image)\n",
    "        else:\n",
    "            mtl[values[0]] = map(float, values[1:])\n",
    "    return contents\n",
    "\n",
    "class OBJ:\n",
    "    def __init__(self, filename, swapyz=False):\n",
    "        \"\"\"Loads a Wavefront OBJ file. \"\"\"\n",
    "        self.vertices = []\n",
    "        self.normals = []\n",
    "        self.texcoords = []\n",
    "        self.faces = []\n",
    "        material = None\n",
    "        for line in open(filename, \"r\"):\n",
    "            if line.startswith('#'): continue\n",
    "            values = line.split()\n",
    "            if not values: continue\n",
    "            if values[0] == 'v':\n",
    "                v = list(map(float, values[1:4]))\n",
    "                if swapyz:\n",
    "                    v = v[0], v[2], v[1]\n",
    "                self.vertices.append(v)\n",
    "            elif values[0] == 'vn':\n",
    "                v = list(map(float, values[1:4]))\n",
    "                if swapyz:\n",
    "                    v = v[0], v[2], v[1]\n",
    "                self.normals.append(v)\n",
    "            elif values[0] == 'vt':\n",
    "                self.texcoords.append(map(float, values[1:3]))\n",
    "#             elif values[0] in ('usemtl', 'usemat'):\n",
    "#                 material = values[1]\n",
    "#             elif values[0] == 'mtllib':\n",
    "#                 self.mtl = MTL(filename.replace(\".obj\",\".mtl\"))\n",
    "            elif values[0] == 'f':\n",
    "                face = []\n",
    "                texcoords = []\n",
    "                norms = []\n",
    "                for v in values[1:]:\n",
    "                    w = v.split('/')\n",
    "                    face.append(int(w[0]))\n",
    "                    if len(w) >= 2 and len(w[1]) > 0:\n",
    "                        texcoords.append(int(w[1]))\n",
    "                    else:\n",
    "                        texcoords.append(0)\n",
    "                    if len(w) >= 3 and len(w[2]) > 0:\n",
    "                        norms.append(int(w[2]))\n",
    "                    else:\n",
    "                        norms.append(0)\n",
    "                #self.faces.append((face, norms, texcoords, material))\n",
    "                self.faces.append((face, norms, texcoords))\n",
    "#         self.gl_list = glGenLists(1)\n",
    "#         glNewList(self.gl_list, GL_COMPILE)\n",
    "#         glEnable(GL_TEXTURE_2D)\n",
    "#         glFrontFace(GL_CCW)\n",
    "#         for face in self.faces:\n",
    "#             vertices, normals, texture_coords, material = face\n",
    "\n",
    "#             mtl = self.mtl[material]\n",
    "#             if 'texture_Kd' in mtl:\n",
    "#                 # use diffuse texmap\n",
    "#                 glBindTexture(GL_TEXTURE_2D, mtl['texture_Kd'])\n",
    "#             else:\n",
    "#                 # just use diffuse colour\n",
    "#                 glColor(*mtl['Kd'])\n",
    "\n",
    "#             glBegin(GL_POLYGON)\n",
    "#             for i in range(len(vertices)):\n",
    "#                 if normals[i] > 0:\n",
    "#                     glNormal3fv(self.normals[normals[i] - 1])\n",
    "#                 if texture_coords[i] > 0:\n",
    "#                     glTexCoord2fv(self.texcoords[texture_coords[i] - 1])\n",
    "#                 glVertex3fv(self.vertices[vertices[i] - 1])\n",
    "#             glEnd()\n",
    "#         glDisable(GL_TEXTURE_2D)\n",
    "#         glEndList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba18f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(img, obj, projection, model, color=False):\n",
    "    \"\"\"\n",
    "    Render a loaded obj model into the current video frame\n",
    "    \"\"\"\n",
    "    vertices = obj.vertices\n",
    "    scale_matrix = np.eye(3) * 3\n",
    "    h, w = model.shape\n",
    "    for face in obj.faces:\n",
    "        face_vertices = face[0]\n",
    "        points = np.array([vertices[vertex - 1] for vertex in face_vertices])\n",
    "        points = np.dot(points, scale_matrix)\n",
    "        # render model in the middle of the reference surface. To do so,\n",
    "        # model points must be displaced\n",
    "        points = np.array([[p[0] + w / 2, p[1] + h / 2, p[2]] for p in points])\n",
    "        dst = cv2.perspectiveTransform(points.reshape(-1, 1, 3), projection)\n",
    "        imgpts = np.int32(dst)\n",
    "        if color is False:\n",
    "            cv2.fillConvexPoly(img, imgpts, DEFAULT_COLOR)\n",
    "        else:\n",
    "            color = hex_to_rgb(face[-1])\n",
    "            color = color[::-1]  # reverse\n",
    "            cv2.fillConvexPoly(img, imgpts, color)\n",
    "\n",
    "    return img\n",
    "\n",
    "def renderObj(img, obj, projection, color=False):\n",
    "    \"\"\"\n",
    "    Render a loaded obj model into the current video frame\n",
    "    \"\"\"\n",
    "    vertices = obj.vertices\n",
    "    scale_matrix = np.eye(3) * 3\n",
    "    h, w = (644,372)\n",
    "    for face in obj.faces:\n",
    "        face_vertices = face[0]\n",
    "        points = np.array([vertices[vertex - 1] for vertex in face_vertices])\n",
    "        points = np.dot(points, scale_matrix)\n",
    "        # render model in the middle of the reference surface. To do so,\n",
    "        # model points must be displaced\n",
    "        points = np.array([[p[0] + w / 2, p[1] + h / 2, p[2]] for p in points])\n",
    "        dst = cv2.perspectiveTransform(points.reshape(-1, 1, 3), projection)\n",
    "        imgpts = np.int32(dst)\n",
    "        if color is False:\n",
    "            cv2.fillConvexPoly(img, imgpts, DEFAULT_COLOR)\n",
    "        else:\n",
    "#             color = hex_to_rgb(face[-1])\n",
    "            color = face[-1]\n",
    "            color = color[::-1]  # reverse\n",
    "            cv2.fillConvexPoly(img, imgpts, color)        \n",
    "\n",
    "    return img\n",
    "def projection_matrix(camera_parameters, homography):\n",
    "    \"\"\"\n",
    "    From the camera calibration matrix and the estimated homography\n",
    "    compute the 3D projection matrix\n",
    "    \"\"\"\n",
    "    # Compute rotation along the x and y axis as well as the translation\n",
    "    homography = homography * (-1)\n",
    "    rot_and_transl = np.dot(np.linalg.inv(camera_parameters), homography)\n",
    "    col_1 = rot_and_transl[:, 0]\n",
    "    col_2 = rot_and_transl[:, 1]\n",
    "    col_3 = rot_and_transl[:, 2]\n",
    "    # normalise vectors\n",
    "    l = math.sqrt(np.linalg.norm(col_1, 2) * np.linalg.norm(col_2, 2))\n",
    "    rot_1 = col_1 / l\n",
    "    rot_2 = col_2 / l\n",
    "    translation = col_3 / l\n",
    "    # compute the orthonormal basis\n",
    "    c = rot_1 + rot_2\n",
    "    p = np.cross(rot_1, rot_2)\n",
    "    d = np.cross(c, p)\n",
    "    rot_1 = np.dot(c / np.linalg.norm(c, 2) + d / np.linalg.norm(d, 2), 1 / math.sqrt(2))\n",
    "    rot_2 = np.dot(c / np.linalg.norm(c, 2) - d / np.linalg.norm(d, 2), 1 / math.sqrt(2))\n",
    "    rot_3 = np.cross(rot_1, rot_2)\n",
    "    # finally, compute the 3D projection matrix from the model to the current frame\n",
    "    projection = np.stack((rot_1, rot_2, rot_3, translation)).T\n",
    "    return np.dot(camera_parameters, projection)\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    \"\"\"\n",
    "    Helper function to convert hex strings to RGB\n",
    "    \"\"\"\n",
    "    print(hex_color)\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    h_len = len(hex_color)\n",
    "    return tuple(int(hex_color[i:i + h_len // 3], 16) for i in range(0, h_len, h_len // 3))\n",
    "\n",
    "def init_feature(name):\n",
    "    chunks = name.split('-')\n",
    "    if chunks[0] == 'sift':\n",
    "        detector = cv2.xfeatures2d.SIFT_create()\n",
    "        norm = cv2.NORM_L2\n",
    "    elif chunks[0] == 'surf':\n",
    "        detector = cv2.xfeatures2d.SURF_create(800)\n",
    "        norm = cv2.NORM_L2\n",
    "    elif chunks[0] == 'orb':\n",
    "        detector = cv2.ORB_create(200)\n",
    "        norm = cv2.NORM_HAMMING\n",
    "    elif chunks[0] == 'akaze':\n",
    "        detector = cv2.AKAZE_create()\n",
    "        norm = cv2.NORM_HAMMING\n",
    "    elif chunks[0] == 'brisk':\n",
    "        detector = cv2.BRISK_create()\n",
    "        norm = cv2.NORM_HAMMING\n",
    "    else:\n",
    "        return None, None\n",
    "    if 'flann' in chunks:\n",
    "        if norm == cv2.NORM_L2:\n",
    "            flann_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        else:\n",
    "            flann_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                               table_number = 6, # 12\n",
    "                               key_size = 12,     # 20\n",
    "                               multi_probe_level = 1) #2\n",
    "        matcher = cv2.FlannBasedMatcher(flann_params, {})  # bug : need to pass empty dict (#1329)\n",
    "    else:\n",
    "        matcher = cv2.BFMatcher(norm)\n",
    "    return detector, matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc4d67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "def getColor(zDist):\n",
    "    c = int(interp(zDist, [0,15], [0,255]))\n",
    "    return (c,c,c)\n",
    "def createLandMarks(hand_landmarks): #-> Mapping[int, mp_drawing.DrawingSpec]:\n",
    "  hand_landmark_style = {}  \n",
    "  for k, v in drawing_styles._HAND_LANDMARK_STYLE.items():\n",
    "    for landmark in k:\n",
    "      c = getColor(abs(hand_landmarks.landmark[landmark].z*100))\n",
    "      r = int(abs(hand_landmarks.landmark[landmark].z*100))\n",
    "      hand_landmark_style[landmark] =   mp_drawing.DrawingSpec(color=c, thickness=drawing_styles._THICKNESS_DOT, circle_radius= r )\n",
    "  return hand_landmark_style   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70933e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2777777777777778\n",
      "0.016666666666666666\n",
      "0.027777777777777776\n",
      "0.05\n",
      "0.05277777777777778\n",
      "0.058333333333333334\n",
      "0.06388888888888888\n",
      "0.06666666666666667\n",
      "0.08333333333333333\n",
      "0.09166666666666666\n",
      "0.11388888888888889\n",
      "0.12222222222222222\n",
      "0.125\n",
      "0.13055555555555556\n",
      "0.14444444444444443\n",
      "0.14722222222222223\n",
      "0.15555555555555556\n",
      "0.15833333333333333\n",
      "0.1638888888888889\n",
      "0.16666666666666666\n",
      "0.16944444444444445\n",
      "0.18055555555555555\n",
      "0.18611111111111112\n",
      "0.18888888888888888\n",
      "0.19722222222222222\n",
      "0.2\n",
      "0.20277777777777778\n",
      "0.20833333333333334\n",
      "0.21944444444444444\n",
      "0.2222222222222222\n",
      "0.2388888888888889\n",
      "0.24444444444444444\n",
      "0.25555555555555554\n",
      "0.25833333333333336\n",
      "0.24722222222222223\n",
      "0.24444444444444444\n",
      "0.2388888888888889\n",
      "0.20555555555555555\n",
      "0.20277777777777778\n",
      "0.2\n",
      "0.18055555555555555\n",
      "0.16111111111111112\n",
      "0.14444444444444443\n",
      "0.14166666666666666\n",
      "0.13333333333333333\n",
      "0.11944444444444445\n",
      "0.11666666666666667\n",
      "0.08333333333333333\n",
      "0.08055555555555556\n",
      "0.06666666666666667\n",
      "0.06388888888888888\n",
      "0.044444444444444446\n",
      "0.041666666666666664\n",
      "0.03333333333333333\n",
      "0.013888888888888888\n",
      "0.011111111111111112\n",
      "0.002777777777777778\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Load 3D model from OBJ file\n",
    "obj1 = OBJ(os.path.join(dir_name, 'models/fox.obj'), swapyz=True)  \n",
    "obj2 = OBJ(os.path.join(dir_name, 'models/rat.obj'), swapyz=True)  \n",
    "projection = np.float32([[     503.33,   -699.16,    503.33,-130131.43],\n",
    "                         [    1500,    -62.98,     40.02,-391977.22],\n",
    "                         [      0.26,      0.22,      0.94,  -1283.31]])\n",
    "camera_parameters = np.array([[800, 0, 320],\n",
    "                              [0, 800, 240],\n",
    "                              [0, 0, 1]])\n",
    "\n",
    "homography =  np.float32([[0.4160569997384721, -1.306889006892538, 553.7055461075881],\n",
    "                          [0.7917584252773352, -0.06341244158456338, -108.2770029401219],\n",
    "                          [0.0005926357240956578, -0.001020651672127799, 1]])\n",
    "createControls = 1\n",
    "counter = 0\n",
    "\n",
    "def on_change(value):\n",
    "    valuelf = value/360\n",
    "    print(valuelf)\n",
    "    homography[1][1] = valuelf    \n",
    "    \n",
    "with mp_hands.Hands(static_image_mode=False,min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "\n",
    "        #Get image H ,W\n",
    "        image_height, image_width, _ = image.shape\n",
    "        \n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand_landmarks  in enumerate(results.multi_hand_landmarks):\n",
    "#                 print(\n",
    "#                     f'Index finger tip coordinates: (',\n",
    "#                     f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "#                     f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height}) '\n",
    "#                     f'{abs(hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].z*100)})'\n",
    "#                 )\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "#                                         mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "#                                         mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),)\n",
    "                                      createLandMarks(hand_landmarks),\n",
    "                                      mp_drawing_styles.get_default_hand_connections_style())                        \n",
    "                                \n",
    "                lnd1 = hand_landmarks.landmark[4]\n",
    "                lnd2 = hand_landmarks.landmark[0]\n",
    "                lnd3 = hand_landmarks.landmark[17]\n",
    "                lnd4 = hand_landmarks.landmark[8]\n",
    "                lndLst = np.array([[lnd1.x*image_width, lnd1.y* image_height],\n",
    "                                  [lnd2.x*image_width, lnd2.y* image_height],\n",
    "                                  [lnd3.x*image_width, lnd3.y* image_height], \n",
    "                                  [lnd4.x*image_width, lnd4.y* image_height],\n",
    "                                  [lnd1.x*image_width, lnd1.y* image_height]]).reshape((-1, 1, 2))\n",
    "                \n",
    "                image = cv2.polylines(image, [np.int32(lndLst)], True, 255, 3, cv2.LINE_AA)\n",
    "                \n",
    "                src_pts = np.float32([0 , 0 ,\n",
    "                                      500, 0,\n",
    "                                      500, 500,\n",
    "                                      0, 500]).reshape(-1, 1, 2)\n",
    "                dst_pts = np.float32([lnd1.x*image_width, lnd1.y* image_height,\n",
    "                                      lnd2.x*image_width, lnd2.y* image_height,\n",
    "                                      lnd3.x*image_width, lnd3.y* image_height,\n",
    "                                      lnd4.x*image_width, lnd4.y* image_height]).reshape(-1, 1, 2) \n",
    "                dst_pts = dst_pts.round(2)\n",
    "                homography, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "                projection = projection_matrix(camera_parameters, homography)  \n",
    "                \n",
    "                if(results.multi_handedness[num].classification[0].label == \"Left\"):\n",
    "                    image = renderObj(image, obj1, projection, True)\n",
    "                else:\n",
    "                    image = renderObj(image, obj2, projection, True)\n",
    "        \n",
    "        plot = np.zeros([image_height, image_width, 3], dtype=np.uint8)                \n",
    "        if results.multi_hand_world_landmarks:\n",
    "            for num,hand_world_landmarks in enumerate(results.multi_hand_world_landmarks):                \n",
    "                for idx,landMrk in enumerate(hand_world_landmarks.landmark):\n",
    "                    hand_world_landmarks.landmark[idx].x += 0.5\n",
    "                    hand_world_landmarks.landmark[idx].y += 0.5\n",
    "                mp_drawing.draw_landmarks(plot,hand_world_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "#                 mp_drawing.plot_landmarks(hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)\n",
    "        \n",
    "        cv2.imshow('Plot', plot)\n",
    "        cv2.imshow('HandTracking', image) \n",
    "\n",
    "        if(createControls):\n",
    "            createControls = 0\n",
    "            cv2.createTrackbar('slider', \"HandTracking\", -100,100, on_change)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed7275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
